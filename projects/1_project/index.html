<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h3 id="-context">🧠 Context</h3> <p>As wearable devices like smart glasses become more prevalent, ensuring that the data they collect is valid — and identifying the actual user — becomes critical. Most systems don’t distinguish between idle data (e.g., glasses left on a desk) and meaningful usage. This project addresses that gap.</p> <hr> <h3 id="-task">🎯 Task</h3> <p>Design a complete, real-time machine learning pipeline to:</p> <ul> <li>Detect whether smart glasses are currently being worn</li> <li>Authenticate the rightful user</li> <li>Identify the individual among a group of users<br> All using only IMU sensor data, running on-device, without deep learning.</li> </ul> <hr> <h3 id="️-approach">⚙️ Approach</h3> <p>We built and evaluated a full ML pipeline using smart glasses’ motion sensor data.<br> Key components:</p> <ul> <li> <strong>Data</strong>: Collected from 17 participants performing 6 predefined head gestures on Epson Moverio BT-350</li> <li> <strong>Sensors</strong>: Accelerometer, Gyroscope, Rotation Vector, Geomagnetic</li> <li> <strong>Features</strong>: Simple time-domain stats (mean, min, max) over 1s windows</li> <li> <strong>Classifiers tested</strong>: <ul> <li>Adaboost</li> <li>Random Forest</li> <li>SVM (RBF/poly)</li> <li>MLP</li> <li>Ensembles (e.g., SVM+MLP)</li> </ul> </li> <li> <strong>Preprocessing</strong>: Sliding window (50% overlap), SMOTE for class imbalance</li> <li> <strong>Evaluation</strong>: Gesture-specific 10-fold cross-validation</li> </ul> <hr> <h3 id="-key-results">📊 Key Results</h3> <div class="row"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/1_project/far_frr_eer-480.webp 480w,/assets/img/projects/1_project/far_frr_eer-800.webp 800w,/assets/img/projects/1_project/far_frr_eer-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/1_project/far_frr_eer.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Authentication Performance (EER/FAR/FRR)" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>The triangle gesture with RotVec + GeoMag sensors achieved an <strong>Equal Error Rate of 1.3%</strong> </li> <li>Adaboost consistently outperformed other models in both authentication and identification tasks</li> </ul> <div class="row"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/1_project/eer_results-480.webp 480w,/assets/img/projects/1_project/eer_results-800.webp 800w,/assets/img/projects/1_project/eer_results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/1_project/eer_results.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Sensor Combination Effect on EER" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>High accuracy was achieved with only <strong>2 sensors</strong>, enabling low-power, on-device deployment</li> <li>Sliding window and SMOTE together significantly improved robustness across users</li> </ul> <hr> <h3 id="-outcome--impact">🧾 Outcome &amp; Impact</h3> <ul> <li>🔒 Enabled secure, personalized interactions with smart glasses without user input</li> <li>⚙️ Designed for embedded deployment using classical ML — no deep learning or cloud needed</li> <li>📈 Validated on real data from 17 users with strong performance</li> <li>📄 Published in SN Computer Science (Springer, 2023)</li> </ul> <p>This project shows how practical ML pipelines — when thoughtfully designed — can solve real-world problems even under compute and power constraints. It demonstrates attention to deployment constraints, responsible data collection, and model evaluation.</p> <hr> <h3 id="-resources">🔗 Resources</h3> <ul> <li>📁 <a href="https://github.com/sumeyye-agac/glass-data-participant-detection" rel="external nofollow noopener" target="_blank">GitHub Repository</a> </li> <li>📄 <a href="https://doi.org/10.1007/s42979-023-02202-4" rel="external nofollow noopener" target="_blank">Published Paper (SN Computer Science)</a> </li> </ul> <hr> <p><strong>Tags:</strong><br> <code class="language-plaintext highlighter-rouge">#UserAuthentication</code> <code class="language-plaintext highlighter-rouge">#Identification</code> <code class="language-plaintext highlighter-rouge">#EdgeAI</code> <code class="language-plaintext highlighter-rouge">#WearableComputing</code> <code class="language-plaintext highlighter-rouge">#SensorFusion</code> <code class="language-plaintext highlighter-rouge">#MachineLearning</code> <code class="language-plaintext highlighter-rouge">#TimeSeriesClassification</code></p> </body></html>