<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h3 id="-user-classification-for-smart-glasses-from-authentication-to-identification">👓 User Classification for Smart Glasses: From Authentication to Identification</h3> <p><strong>A real-time system for detecting user presence, authenticating, and identifying individuals via motion sensor data from smart glasses — optimized for wearable deployment.</strong></p> <hr> <h3 id="-project-overview">🎯 Project Overview</h3> <p>This project addresses a practical challenge in wearable computing: determining whether a smart glass device is actively being worn. The system classifies time-series IMU data to enable presence-aware filtering and supports secure, personalized use through user authentication and identification.</p> <hr> <h3 id="-motivation">💡 Motivation</h3> <p>Smart glasses and similar wearables collect continuous motion data, but not all of it is valid or meaningful. Detecting user presence before running downstream models like HAR or authentication improves data quality, conserves power, and enhances security.</p> <hr> <h3 id="️-system-design">⚙️ System Design</h3> <div class="row"> <div class="col-sm-12 mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/1_project/architecture-480.webp 480w,/assets/img/projects/1_project/architecture-800.webp 800w,/assets/img/projects/1_project/architecture-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/1_project/architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="System Pipeline" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>The system processes raw IMU signals, extracts time-domain features, and classifies windows as either user or no-user. When a user is present, additional authentication and identification stages can be triggered — all designed for real-time execution on wearable hardware.</p> <hr> <h3 id="-data-collection--gesture-design">🧪 Data Collection &amp; Gesture Design</h3> <div class="row"> <div class="col-sm-12 mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/1_project/head_movements-480.webp 480w,/assets/img/projects/1_project/head_movements-800.webp 800w,/assets/img/projects/1_project/head_movements-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/1_project/head_movements.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Gesture Set" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li>17 participants</li> <li>6 head gestures: circle, up-down, tilt, triangle, turn, square</li> <li>Device: Epson Moverio BT-350 smart glasses</li> <li>Sensors: Accelerometer, Gyroscope, Rotation Vector, Geomagnetic</li> <li>Sampling: 110 Hz / 55 Hz</li> </ul> <p>Data was segmented into 1-second windows, with simple features (mean, min, max) computed per axis and sensor — enabling efficient modeling with limited compute.</p> <hr> <h3 id="-signal-patterns-across-users">📉 Signal Patterns Across Users</h3> <div class="row"> <div class="col-sm-12 mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/1_project/3dplots-480.webp 480w,/assets/img/projects/1_project/3dplots-800.webp 800w,/assets/img/projects/1_project/3dplots-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/1_project/3dplots.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="3D IMU Traces by User" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Variability in gesture patterns across users formed the basis for behavioral biometric classification — essential for reliable authentication and identification.</p> <hr> <h3 id="-results">📊 Results</h3> <div class="row"> <div class="col-sm-6 mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/1_project/classifiers-480.webp 480w,/assets/img/projects/1_project/classifiers-800.webp 800w,/assets/img/projects/1_project/classifiers-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/1_project/classifiers.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Classifier Comparison" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-6 mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/1_project/far_frr_eer-480.webp 480w,/assets/img/projects/1_project/far_frr_eer-800.webp 800w,/assets/img/projects/1_project/far_frr_eer-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/1_project/far_frr_eer.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="EER / FAR / FRR per Gesture" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <strong>Authentication</strong>: Achieved 1.3% EER using triangle gesture and RotVec + GeoMag sensors</li> <li> <strong>Identification</strong>: 99.3% F1-score with Random Forest using 3-sensor fusion</li> <li>Adaboost outperformed other models in most gesture-sensor settings</li> <li>Applied sliding window overlap and SMOTE to handle sequential structure and class imbalance</li> </ul> <div class="row"> <div class="col-sm-6 mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/1_project/participant_based2-480.webp 480w,/assets/img/projects/1_project/participant_based2-800.webp 800w,/assets/img/projects/1_project/participant_based2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/1_project/participant_based2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Error Reduction with Optimizations" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-6 mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/projects/1_project/eer_results-480.webp 480w,/assets/img/projects/1_project/eer_results-800.webp 800w,/assets/img/projects/1_project/eer_results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/projects/1_project/eer_results.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Sensor Fusion Results" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <h3 id="-highlights">✅ Highlights</h3> <ul> <li>End-to-end classification system for <strong>user authentication, and identification</strong> </li> <li>Works in using <strong>only time-domain features</strong> (mean, min, max)</li> <li>Demonstrated state-of-the-art performance with <strong>minimal sensor combinations</strong> </li> <li>System optimized for <strong>resource-limited wearable deployment</strong> </li> <li>Research published in <em>SN Computer Science</em> (Springer, 2023)</li> </ul> <hr> <h3 id="-resources">🔗 Resources</h3> <ul> <li>📁 <a href="https://github.com/sumeyye-agac/glass-data-participant-detection" rel="external nofollow noopener" target="_blank">GitHub Repository</a> </li> <li>📄 <a href="https://doi.org/10.1007/s42979-023-02202-4" rel="external nofollow noopener" target="_blank">Published Paper (SN Computer Science)</a> </li> </ul> <p><strong>Tags:</strong> <code class="language-plaintext highlighter-rouge">#MachineLearning</code> <code class="language-plaintext highlighter-rouge">#Wearables</code> <code class="language-plaintext highlighter-rouge">#EdgeAI</code> <code class="language-plaintext highlighter-rouge">#SensorFusion</code> <code class="language-plaintext highlighter-rouge">#IMU</code> <code class="language-plaintext highlighter-rouge">#BehavioralBiometrics</code> <code class="language-plaintext highlighter-rouge">#TimeSeries</code></p> </body></html>